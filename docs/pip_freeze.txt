# Core LLM tooling (LoRA / PEFT) ΓÇö pinned for reproducible Windows builds
transformers==4.46.3
datasets==2.21.0
accelerate==0.34.2
peft==0.13.2
safetensors==0.4.5

# HF tokenizer/model deps (Windows-friendly)
tokenizers==0.20.1
sentencepiece==0.2.0
protobuf==4.25.5
# Quality-of-life + numeric stack (pin to avoid ABI weirdness)
tqdm==4.67.1
numpy==1.26.4
## The following requirements were added by pip freeze:
aiohappyeyeballs==2.6.1
aiohttp==3.13.2
aiosignal==1.4.0
async-timeout==5.0.1
attrs==25.4.0
certifi==2025.11.12
charset-normalizer==3.4.4
colorama==0.4.6
dill==0.3.8
filelock==3.20.1
frozenlist==1.8.0
fsspec==2024.6.1
huggingface-hub==0.36.0
idna==3.11
Jinja2==3.1.6
MarkupSafe==3.0.3
mpmath==1.3.0
multidict==6.7.0
multiprocess==0.70.16
networkx==3.4.2
packaging==25.0
pandas==2.3.3
propcache==0.4.1
psutil==7.2.0
pyarrow==22.0.0
python-dateutil==2.9.0.post0
pytz==2025.2
PyYAML==6.0.3
regex==2025.11.3
requests==2.32.5
six==1.17.0
sympy==1.14.0
torch==2.9.1
typing_extensions==4.15.0
tzdata==2025.3
urllib3==2.6.2
xxhash==3.6.0
yarl==1.22.0
